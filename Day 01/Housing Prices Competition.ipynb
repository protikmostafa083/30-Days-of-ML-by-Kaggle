{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T07:11:30.987367Z","iopub.execute_input":"2021-08-17T07:11:30.987783Z","iopub.status.idle":"2021-08-17T07:11:31.000863Z","shell.execute_reply.started":"2021-08-17T07:11:30.987747Z","shell.execute_reply":"2021-08-17T07:11:30.999875Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import helpful libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Load the data, and separate the target\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\nhome_data = pd.read_csv(iowa_file_path)\ny = home_data.SalePrice\n\n# Create X (After completing the exercise, you can return to modify this line!)\nfeatures = [\n    'MSSubClass',\n    'LotArea',\n    'OverallQual' ,\n    'OverallCond' ,\n    'YearBuilt',\n    'YearRemodAdd' ,\n    '1stFlrSF',\n    '2ndFlrSF' ,\n    'LowQualFinSF' ,\n    'GrLivArea',\n    'FullBath',\n    'HalfBath',\n    'BedroomAbvGr' ,\n    'KitchenAbvGr' ,\n    'TotRmsAbvGrd' ,\n    'Fireplaces' ,\n    'WoodDeckSF' ,\n    'OpenPorchSF',\n    'EnclosedPorch' ,\n    '3SsnPorch' ,\n    'ScreenPorch' ,\n    'PoolArea' ,\n    'MiscVal' ,\n    'MoSold' ,\n    'YrSold',\n]\n\n# Select columns corresponding to features, and preview the data\nX = home_data[features]\n\nX.head()\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Define a random forest model\nrf_model = RandomForestRegressor(random_state=1, n_estimators = 700, max_leaf_nodes = 221)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\nrf_val_rmse = np.sqrt(mean_squared_error(rf_val_predictions, val_y))\n\n\n\n# Define a GBM\ngbm_model = GradientBoostingRegressor(random_state=1, n_estimators = 72)\ngbm_model.fit(train_X, train_y)\ngbm_val_predictions = gbm_model.predict(val_X)\ngbm_val_mae = mean_absolute_error(gbm_val_predictions, val_y)\ngbm_val_rmse = np.sqrt(mean_squared_error(gbm_val_predictions, val_y))\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\nprint(f\"Validation RMSE for Random Forest Model: {int(rf_val_rmse)}\")\n\nprint(\"Validation MAE for GBM: {:,.0f}\".format(gbm_val_mae))\nprint(f\"Validation RMSE for GBM: {int(gbm_val_rmse)}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:31.002750Z","iopub.execute_input":"2021-08-17T07:11:31.003325Z","iopub.status.idle":"2021-08-17T07:11:36.955292Z","shell.execute_reply.started":"2021-08-17T07:11:31.003278Z","shell.execute_reply":"2021-08-17T07:11:36.954254Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Validation MAE for Random Forest Model: 17,877\nValidation RMSE for Random Forest Model: 26737\nValidation MAE for GBM: 16,808\nValidation RMSE for GBM: 24415\n","output_type":"stream"}]},{"cell_type":"code","source":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor(random_state=1, n_estimators = 72, max_leaf_nodes = 221)\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model_on_full_data.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:36.957316Z","iopub.execute_input":"2021-08-17T07:11:36.957626Z","iopub.status.idle":"2021-08-17T07:11:37.683423Z","shell.execute_reply.started":"2021-08-17T07:11:36.957598Z","shell.execute_reply":"2021-08-17T07:11:37.682615Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(max_leaf_nodes=221, n_estimators=72, random_state=1)"},"metadata":{}}]},{"cell_type":"code","source":"# To improve accuracy, create a new Random Forest model which you will train on all training data\ngbm_model_on_full_data = GradientBoostingRegressor(random_state=1, n_estimators = 72, max_leaf_nodes = 221)\n\n# fit rf_model_on_full_data on all data from the training data\ngbm_model_on_full_data.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:37.684678Z","iopub.execute_input":"2021-08-17T07:11:37.685109Z","iopub.status.idle":"2021-08-17T07:11:37.972936Z","shell.execute_reply.started":"2021-08-17T07:11:37.685062Z","shell.execute_reply":"2021-08-17T07:11:37.972161Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"GradientBoostingRegressor(max_leaf_nodes=221, n_estimators=72, random_state=1)"},"metadata":{}}]},{"cell_type":"code","source":"# path to file you will use for predictions\ntest_data_path = '../input/home-data-for-ml-course/test.csv.gz'\n\n# read test data file using pandas\ntest_data = pd.read_csv(test_data_path)\ntest_data = test_data.fillna(-1)\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[features]\n\n# make predictions which we will submit. \ntest_preds1 = rf_model_on_full_data.predict(test_X)\ntest_preds2 = gbm_model_on_full_data.predict(test_X)\ntest_preds = (test_preds1 + test_preds2) / 2","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:37.973936Z","iopub.execute_input":"2021-08-17T07:11:37.974587Z","iopub.status.idle":"2021-08-17T07:11:38.045515Z","shell.execute_reply.started":"2021-08-17T07:11:37.974552Z","shell.execute_reply":"2021-08-17T07:11:38.044657Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Run the code to save predictions in the format used for competition scoring\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:38.046519Z","iopub.execute_input":"2021-08-17T07:11:38.046923Z","iopub.status.idle":"2021-08-17T07:11:38.058629Z","shell.execute_reply.started":"2021-08-17T07:11:38.046894Z","shell.execute_reply":"2021-08-17T07:11:38.057515Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"output.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T07:11:38.059699Z","iopub.execute_input":"2021-08-17T07:11:38.059987Z","iopub.status.idle":"2021-08-17T07:11:38.072515Z","shell.execute_reply.started":"2021-08-17T07:11:38.059960Z","shell.execute_reply":"2021-08-17T07:11:38.071428Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"     Id      SalePrice\n0  1461  125831.148619\n1  1462  157848.249840\n2  1463  172436.062527\n3  1464  181019.612655\n4  1465  203555.713649","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>125831.148619</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>157848.249840</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>172436.062527</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>181019.612655</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>203555.713649</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}